{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d209d1f9-20d3-4511-8bbf-d01949686130",
   "metadata": {},
   "source": [
    "# Loading concordances into FlexiConc\n",
    "\n",
    "This notebook demonstrates how to load concordances into FlexiConc from various supported concordancing tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ded64f-ab96-43e3-b3c8-57bb3e7b4ef8",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Make sure that FlexiConc and its dependencies are installed, following the instructions in the course slides (which will also install Python packages required by some of the algorithms included in the FlexiConc distribution). Don't forget to activate your virtual environment before starting the JupyterLab server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59ea3b-093b-41ec-8ea4-9c2dff9ddf54",
   "metadata": {},
   "source": [
    "The code cell below is only needed when running this notebook in Google Colab. It uses `!` to run a shell command from the notebook because manual software installation is not supported in Colab. The `-U` upgrades FlexiConc if it is already installed (we frequently release minor or major upgrades). We do not install any extensions as we only want to demonstrate the concordance retrieval functions. For serious concordance reading, the additional dependencies should be installed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10537535-0400-4055-a59b-7b2cea279e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U flexiconc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afdbb85-2df1-480d-b1af-c4fb4658c26e",
   "metadata": {},
   "source": [
    "We can now import FlexiConc and its convenience functions for Jupyter notebooks. Most concordance retrieval functions are automatically available as methods of the `Concordance` object. Only `wmatrix` is a special case that needs to be imported separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d3ac7-ab10-4dea-bb17-6c2096f47b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexiconc import Concordance\n",
    "from flexiconc.utils.notebook_utils import add_node_ui, add_annotation_ui, show_kwic, show_analysis_tree\n",
    "from flexiconc.utils import wmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10041bfd-45a0-4ea1-a217-78fd33174cc4",
   "metadata": {},
   "source": [
    "Note that many of the code cells below require a password, access token, or other special provisions in order to work. It is recommended to focus on the approaches that you need in your work and/or concordancing tools you already have access to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40921d9-f6ef-4ee9-abbf-5d893ddfefad",
   "metadata": {},
   "source": [
    "## CLiC\n",
    "\n",
    "The easiest approach is to load concordance data from the public [CLiC server](https://clic-fiction.com), which is freely accessible without a user account.\n",
    "\n",
    "As an example we load a concordance for _eyes_ within long suspensions across both 19C (19th century novels) and DNov (Charles Dickens) corpora. Read the method docmentation for further information about the arguments and available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c20957-2ce0-418b-9059-965d013e7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Concordance()\n",
    "C.retrieve_from_clic(query=['eyes'], \n",
    "                     corpora=[\"corpus:19C\", \"corpus:DNov\"], subset=\"longsus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1fbd9-d09e-4fb0-b867-513e483aa7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(C.retrieve_from_clic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1435b-c43a-42dc-aa82-cdeab6c166ef",
   "metadata": {},
   "source": [
    "Recall that you can get a glimpse of each concordance with `show_kwic()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e60d38-b03d-47bc-8677-72cc70b513b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_kwic(C.root, n=10, metadata_columns=(\"text_id\", \"chapter\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d0e40-ecef-465f-a964-cee2295f1add",
   "metadata": {},
   "source": [
    "In the following examples, we will usually just display the number of concordance lines in order to demonstrate that the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf46d5f-7ba6-4f02-a8c3-2809b49ba5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.root.line_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335ee56-11e7-4945-9c86-b7bcc13f63a7",
   "metadata": {},
   "source": [
    "## Sketch Engine\n",
    "\n",
    "If you have an account for the commercial [Sketch Engine](https://app.sketchengine.eu/) platform, you can load concordances in a similar way. SkE includes rich token-level annotation, but its support for line-level metadata is rather limited. You will be able to access both your own corpora (_user corpora_) as well as a wide range of pre-installed corpora in many languages.\n",
    "\n",
    "As preparation you need to note down the full path of the relevant corpus, as well as generate an API access token. Both steps are illustrated in the course slides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63804e1-a42d-403a-a27f-73da60231b80",
   "metadata": {},
   "source": [
    "Here, we search for the phrase _fake news_ in the Trump Twitter Archive corpus. It is a user corpus of the account `SEvert`, to which the access token used below also belongs. Note that by the time you run this notebook, the access token has likely been invalidated and you will need to obtain your own access token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab301dc-88e2-4ab4-bf18-d5ad62333252",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Concordance()\n",
    "C.retrieve_from_sketchengine(query='[lc=\"fake\"] [lc=\"news\"]', \n",
    "                             corpus=\"user/SEvert/tta\", \n",
    "                             api_key=\"[YOUR API KEY]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6911929-fe8c-4fab-b577-6ae3a36ba0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.root.line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c440c-5d7d-4ac2-8dd9-05515f7e47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_kwic(C.root, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3c72b-8110-4cb0-9bc0-3eb88609170c",
   "metadata": {},
   "source": [
    "## CQPweb\n",
    "\n",
    "There is no direct interface to [CQPweb servers](https://corpora.linguistik.uni-erlangen.de/cqpweb/) yet (due to the lack of a fully functional API), but you can download concordance data from a CQPweb session and import it into FlexiConc. After running a corpus query, select the _Download â€¦_ action and adjust format options as explained in the course slides. Put the download file (which should automatically be saved with extension `.txt`) in the same folder as this Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd54ba-6d27-42fc-a173-1120ee2be30e",
   "metadata": {},
   "source": [
    "A sample concordance download for _water and sanitation_ in the ParlSpeech UK corpus can be downloaded from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265251d5-d78c-41c9-a210-fe4f3bb5ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://github.com/reading-concordances/teaching/raw/refs/heads/main/course/data/CQPweb_WaterSanitation_ParlUK.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8afdb3-0862-4f0b-bebe-e81d5bd9d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Concordance()\n",
    "C.load_from_cqpweb_export(\"CQPweb_WaterSanitation_ParlUK.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7e462-9ce4-4532-a763-2c37b5fae36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.root.line_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672313d-1c28-4735-a2fe-8887f6dc76a1",
   "metadata": {},
   "source": [
    "Any metadata included in the download file are automatically imported into FlexiCon. `URL` provides a link to display extended context for a concordance line on the CQPweb server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fbeb8-1f58-4a2f-ad2a-fbb38071bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d9930-867c-456d-ae2e-ecd47e19183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.metadata.URL[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fb153-cbf4-478f-bf59-da15d049b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_kwic(C.root, n=10, metadata_columns=(\"Date\", \"Party\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51181fa-2f2c-4a11-b7d5-4d708ae04db9",
   "metadata": {},
   "source": [
    "## WMatrix\n",
    "\n",
    "[WMatrix](https://ucrel-wmatrix7.lancaster.ac.uk/) is a specialised online tool with two main purposes:\n",
    "\n",
    "- You can upload text files and have them automatically compiled into a corpus annotated with part-of-speech tags, lemmata and semantic tags (_concepts_). Metadata can be encoded in the filenames.\n",
    "- It then provides keyword analysis on the annotated corpus at the level of word forms, lemmata, POS tags, and concepts.\n",
    "\n",
    "The concordance display for individual keywords is rather basic, so FlexiConc makes for an ideal companion software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b902fc8-b8bc-4639-865e-14cf5b4ca690",
   "metadata": {},
   "source": [
    "Connecting WMatrix to FlexiConc works differently than for the other tools. Rather than export each individual concordance separately, FlexiConc has to download the entire annotated corpus from WMatrix in its internal SQLite format. You can then create concordances for single words and multiword units. This is convenient because you will typically want to look at concordances for multiple keywords brought up by WMatrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d5f97-25f9-4eff-a575-dd17cf65f5cf",
   "metadata": {},
   "source": [
    "In order to try the example below, you first have to copy the `LabourManifesto2005` corpus from the WMatrix library to your own user account. Then insert your login and password in the respective function arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa5eb69-2807-43cf-925e-c54dad0a40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour2005 = wmatrix.load(\n",
    "    corpus_name=\"LabourManifesto2005\",\n",
    "    username=\"[USER]\",\n",
    "    password=\"[PASSWORD]\",\n",
    "    db_filename=\"labour2005.db\")\n",
    "labour2005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db021a8b-9e1e-4e5d-8932-2b4dbf0f9a87",
   "metadata": {},
   "source": [
    "Creating a concordance is easy for a single word or multiword unit at wordform level. Keep in mind that the search is case-sensitive here so this will often miss some instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd2c63-0f7a-40f7-8c97-eee84125ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = labour2005.concordance_from_query('antisocial behaviour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef462f-b621-4af0-a862-8efb7e7d75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.root.line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13022393-5069-43ab-be67-3b55294c39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_kwic(C.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10aa64f-582e-4ed2-9a63-4091bfae1392",
   "metadata": {},
   "source": [
    "In order to search for lemmas or concepts, you need to specify a query in a vaguely CQP-like notation. Token-level annotations are accessed under the names\n",
    "- `word`: literal word forms\n",
    "- `lemma`: lemmata\n",
    "- `pos`: POS tags\n",
    "- `sem`: concepts = semantic tags\n",
    "You can find suitable values for your search through the keyword analysis functions in WMatrix. The `%c` flag carries out a case-insensitive search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a372a88-b2dc-4106-8b83-9bc3a8637480",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = labour2005.concordance_from_query(r'[lemma=\"community\" %c]')\n",
    "C.root.line_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5f5ed-00b5-457c-9448-b7136f6dd9a9",
   "metadata": {},
   "source": [
    "The WMatrix corpus needs to be downloaded only once and will then be stored locally in the specified file. Next time you access this corpus, you can simply load it from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1a6e3-cc4a-42d3-af70-c8721f401e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour2005 = wmatrix.load(db_filename=\"labour2005.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585ce4a-2fd2-46ad-9949-73aeec003b2e",
   "metadata": {},
   "source": [
    "For your convenience, we have created a corpus `ESSLLI_Water_ParlUK` in the public WMatrix library, which includes all sentences containing the noun _water_ from the ParlSpeech UK corpus. This is still a large download of close to 1 GB, so we also provide a pre-processed version for use with FlexiConc.\n",
    "\n",
    "Download the file `WMatrix_Water_ParlUK.db` and save it to the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16519276-a90b-4885-b877-b4f5efd12a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://github.com/reading-concordances/teaching/raw/refs/heads/main/course/data/WMatrix_Water_ParlUK.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ca44e-3791-4e44-804e-81b679620a68",
   "metadata": {},
   "source": [
    "You can now load the pre-processed corpus into FlexiConc and continue exploring water discourses in the UK parliament, using the keyword analyses of WMatrix as an entry point into the discourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2be9cb-44fb-4eed-9222-670f8d5323e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "water = wmatrix.load(db_filename=\"WMatrix_Water_ParlUK.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af5fbc-cac5-4f64-b241-705b9be0fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = water.concordance_from_query(r'[lemma=\"water\"] [lemma=\"and\"] [lemma=\"sanitation\"]')\n",
    "C.root.line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5862e192-1771-4b95-88e8-3f54df3cafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = C.root.add_subset_node(\n",
    "    (\"Random Sample\",\n",
    "     {'sample_size': 20, 'seed': 42}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff68e53-bd0f-4e80-be44-6c324b1fda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_kwic(n1, metadata_columns=[\"file.file\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
